{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Impor dan Eksplorasi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, matplotlib as mpl, matplotlib.pyplot as plt, pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_1 = pd.read_csv('HR_comma_sep.csv')\n",
    "df_data_2 = pd.read_csv('WA_Fn-UseC_-HR-Employee-Attrition.csv')\n",
    "df_data_3 = pd.read_csv('turnover.csv', encoding = 'ISO-8859-1')\n",
    "df_model_1 = df_data_1.copy()\n",
    "df_model_2 = df_data_2.copy()\n",
    "df_model_3 = df_data_3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   satisfaction_level     14999 non-null  float64\n",
      " 1   last_evaluation        14999 non-null  float64\n",
      " 2   number_project         14999 non-null  int64  \n",
      " 3   average_montly_hours   14999 non-null  int64  \n",
      " 4   time_spend_company     14999 non-null  int64  \n",
      " 5   Work_accident          14999 non-null  int64  \n",
      " 6   left                   14999 non-null  int64  \n",
      " 7   promotion_last_5years  14999 non-null  int64  \n",
      " 8   Department             14999 non-null  object \n",
      " 9   salary                 14999 non-null  object \n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_model_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pengecekan data null untuk dataset 1-3\n",
    "display(df_data_1.isnull().values.any())\n",
    "display(df_data_2.isnull().values.any())\n",
    "display(df_data_3.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deklarasi kolom yang akan dihapus\n",
    "drop2 = ['EmployeeCount', 'EmployeeNumber', 'StandardHours', 'Over18']\n",
    "# drop kolom yang akan dihapus\n",
    "df_model_2 = df_model_2.drop(drop2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename kolom target\n",
    "df_model_1 = df_model_1.rename(columns={'left': 'churn'})\n",
    "df_model_2 = df_model_2.rename(columns={'Attrition': 'churn'})\n",
    "df_model_3 = df_model_3.rename(columns={'event': 'churn'})\n",
    "\n",
    "# rename kolom treatment\n",
    "df_model_1 = df_model_1.rename(columns={'promotion_last_5years': 'treatment'})\n",
    "df_model_2 = df_model_2.rename(columns={'OverTime': 'treatment'})\n",
    "df_model_3 = df_model_3.rename(columns={'coach': 'treatment'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'salary'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['low', 'medium', 'high'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'churn'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'No'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'treatment'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'No'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'BusinessTravel'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['Travel_Rarely', 'Travel_Frequently', 'Non-Travel'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'treatment'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['no', 'yes', 'my head'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# deklarasi kolom string\n",
    "string1, string2, string3 = ['salary'], ['churn',\n",
    "                                         'treatment',\n",
    "                                         'BusinessTravel'], ['treatment']\n",
    "# observasi data unique\n",
    "for col in string1:\n",
    "    display(col, df_model_1[col].unique())\n",
    "for col in string2:\n",
    "    display(col, df_model_2[col].unique())\n",
    "for col in string3:\n",
    "    display(col, df_model_3[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deklarasi target dan treatment dataset 1\n",
    "df_model_1.salary = df_model_1.salary.map({'low': 0, 'medium': 1, 'high':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deklarasi target dan treatment dataset 2\n",
    "df_model_2.churn = df_model_2.churn.map({'Yes': 1, 'No': 0})\n",
    "df_model_2.treatment = df_model_2.treatment.map({'Yes': 0, 'No': 1})\n",
    "# Deklarasi BusinessTravel\n",
    "df_model_2.BusinessTravel = df_model_2.BusinessTravel.map({'Non-Travel': 0,\n",
    "                                                           'Travel_Rarely': 1,\n",
    "                                                           'Travel_Frequently':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Deklarasi target dan treatment dataset 3\n",
    "df_model_3.treatment = df_model_3.treatment.map({'yes': 0, 'no': 1, 'my head':2})\n",
    "df_model_3 = df_model_3.loc[df_model_3.treatment <=1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One-Hot Encoding untuk ketiga dataset:\n",
    "df_model_1, df_model_inverse_1 = pd.get_dummies(df_model_1), pd.get_dummies(df_model_1)\n",
    "df_model_2, df_model_inverse_2 = pd.get_dummies(df_model_2), pd.get_dummies(df_model_2)\n",
    "df_model_3, df_model_inverse_3 = pd.get_dummies(df_model_3), pd.get_dummies(df_model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# kalkulasi korelasi treatment \n",
    "def korelasi_treatment(df:pd.DataFrame):\n",
    "    correlation = df[['treatment','churn']].corr(method ='pearson') \n",
    "    return(pd.DataFrame(round(correlation.loc['churn'] * 100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-24.61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-4.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(korelasi_treatment(df_model_1).iloc[0,0])\n",
    "display(korelasi_treatment(df_model_2).iloc[0,0])\n",
    "display(korelasi_treatment(df_model_3).iloc[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3.3.4. Pendeklarasian Target Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi untuk menambah feature target class\n",
    "def deklarasi_target_class(df:pd.DataFrame):\n",
    "    \"\"\"Fungsi untuk mendeklarasikan target class\n",
    "    \"\"\"\n",
    "    #CN:\n",
    "    df['target_class'] = 0 \n",
    "    #CR:\n",
    "    df.loc[(df.treatment == 0) & (df.churn == 0),'target_class'] = 1 \n",
    "    #TN:\n",
    "    df.loc[(df.treatment == 1) & (df.churn == 1),'target_class'] = 2 \n",
    "    #TR:\n",
    "    df.loc[(df.treatment == 1) & (df.churn == 0),'target_class'] = 3 \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menambah feature target class pada ketiga dataset\n",
    "df_model_1, df_model_2, df_model_3 = deklarasi_target_class(df_model_1), \\\n",
    "deklarasi_target_class(df_model_2), deklarasi_target_class(df_model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 3.4. Hasil Pemodelan Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "def split_data(df_model:pd.DataFrame):\n",
    "    \"\"\"Split data menjadi data train dan data test\n",
    "    \"\"\"\n",
    "    X = df_model.drop(['churn','target_class'],axis=1)\n",
    "    y = df_model.churn\n",
    "    z = df_model.target_class\n",
    "    X_train, X_test, \\\n",
    "    y_train, y_test, \\\n",
    "    z_train, z_test = train_test_split(X,\n",
    "                                       y,\n",
    "                                       z,\n",
    "                                       test_size=0.3,\n",
    "                                       random_state=42,\n",
    "                                       stratify=df_model['treatment'])\n",
    "    return X_train,X_test, y_train, y_test, z_train, z_test\n",
    "\n",
    "\n",
    "def proses_machine_learning(X_train:pd.DataFrame,\n",
    "                            X_test:pd.DataFrame,\n",
    "                            y_train:pd.DataFrame,\n",
    "                            y_test:pd.DataFrame,\n",
    "                            z_train:pd.DataFrame,\n",
    "                            z_test:pd.DataFrame):\n",
    "    \"\"\"Proses machine learning dengan algoritma XGB\n",
    "    \"\"\"\n",
    "    # Siapkan dataframe baru hasil prediksi\n",
    "    hasil_prediksi = pd.DataFrame(X_test).copy()\n",
    "    \n",
    "    \n",
    "    # Proses train model CP\n",
    "    model_cp \\\n",
    "    = xgb.XGBClassifier().fit(X_train.drop('treatment', axis=1), y_train)  \n",
    "    # Proses prediksi model CP\n",
    "    prediksi_cp \\\n",
    "    = model_cp.predict(X_test.drop('treatment',axis=1))\n",
    "    probabilitas_cp \\\n",
    "    = model_cp.predict_proba(X_test.drop('treatment', axis=1))\n",
    "    hasil_prediksi['prediksi_churn'] = prediksi_cp\n",
    "    hasil_prediksi['proba_churn'] = probabilitas_cp[:,1]\n",
    "    \n",
    "    \n",
    "    # Proses train model Uplift\n",
    "    model_uplift \\\n",
    "    = xgb.XGBClassifier().fit(X_train.drop('treatment', axis=1), z_train)\n",
    "    # Proses prediksi model Uplift\n",
    "    prediksi_uplift \\\n",
    "    = model_uplift.predict(X_test.drop('treatment', axis=1))\n",
    "    probabilitas_uplift \\\n",
    "    = model_uplift.predict_proba(X_test.drop('treatment', axis=1))\n",
    "    hasil_prediksi['prediksi_target_class'] = prediksi_uplift\n",
    "    hasil_prediksi['proba_CN'] = probabilitas_uplift[:,0] \n",
    "    hasil_prediksi['proba_CR'] = probabilitas_uplift[:,1] \n",
    "    hasil_prediksi['proba_TN'] = probabilitas_uplift[:,2] \n",
    "    hasil_prediksi['proba_TR'] = probabilitas_uplift[:,3]\n",
    "    hasil_prediksi['skor_uplift'] = hasil_prediksi.eval('\\\n",
    "    proba_CN/(proba_CN+proba_CR) \\\n",
    "    + proba_TR/(proba_TN+proba_TR) \\\n",
    "    - proba_TN/(proba_TN+proba_TR) \\\n",
    "    - proba_CR/(proba_CN+proba_CR)')  \n",
    "    \n",
    "    \n",
    "    # Memasukkan validasi churn dan target class ke dataframe\n",
    "    hasil_prediksi['churn'] = y_test\n",
    "    hasil_prediksi['target_class'] = z_test\n",
    "    return hasil_prediksi\n",
    "\n",
    "\n",
    "def model_machine_learning(df_model:pd.DataFrame):\n",
    "    \"\"\"Menggabungkan proses split dan machine learning\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test, z_train, z_test = split_data(df_model)\n",
    "    hasil_prediksi = proses_machine_learning(X_train,\n",
    "                                             X_test,\n",
    "                                             y_train,\n",
    "                                             y_test,\n",
    "                                             z_train,\n",
    "                                             z_test)\n",
    "    return hasil_prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Proses pemodelan machine learning\n",
    "hasil_prediksi_1 = model_machine_learning(df_model_1)\n",
    "hasil_prediksi_2 = model_machine_learning(df_model_2)\n",
    "hasil_prediksi_3 = model_machine_learning(df_model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 3.5.1. Evaluasi Akurasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, multilabel_confusion_matrix\n",
    "def evaluasi_akurasi(df:pd.DataFrame):\n",
    "    \"\"\"Evaluasi akurasi hasil prediksi\n",
    "    \"\"\"\n",
    "    print(\"ETP's confusion matrix result\")\n",
    "    confusion_etp = confusion_matrix(df['churn'], df['prediksi_churn'])\n",
    "    tn, fp, fn, tp = confusion_etp.ravel()\n",
    "    confusion_etp = pd.DataFrame(confusion_etp, columns = ['True','False'], index = ['Positive','Negative'])\n",
    "    display(confusion_etp)\n",
    "    \n",
    "    \n",
    "    print(\"ETU's confusion matrix result\")   \n",
    "    confusion_etu = multilabel_confusion_matrix(df['target_class'], df['prediksi_target_class'])\n",
    "    display(confusion_etu)\n",
    "    \n",
    "    \n",
    "    akurasi_cp = accuracy_score(df['churn'],\n",
    "                                df['prediksi_churn'])\n",
    "    print('Akurasi model CP: %.2f%%' % (akurasi_cp * 100.0))\n",
    "    \n",
    "    \n",
    "    akurasi_uplift = accuracy_score(df['target_class'],\n",
    "                                    df['prediksi_target_class'])\n",
    "    print('Akurasi model Uplift: %.2f%%' % (akurasi_uplift * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETP's confusion matrix result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>3392</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>83</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          True  False\n",
       "Positive  3392     44\n",
       "Negative    83    981"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETU's confusion matrix result\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[3390,   53],\n",
       "        [  81,  976]],\n",
       "\n",
       "       [[ 991,  162],\n",
       "        [  49, 3298]],\n",
       "\n",
       "       [[4493,    0],\n",
       "        [   7,    0]],\n",
       "\n",
       "       [[4408,    3],\n",
       "        [  81,    8]]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi model CP: 97.18%\n",
      "Akurasi model Uplift: 95.16%\n",
      "ETP's confusion matrix result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>374</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          True  False\n",
       "Positive   374      4\n",
       "Negative    52     11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETU's confusion matrix result\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[406,   6],\n",
       "        [ 29,   0]],\n",
       "\n",
       "       [[331,  14],\n",
       "        [ 95,   1]],\n",
       "\n",
       "       [[406,   1],\n",
       "        [ 33,   1]],\n",
       "\n",
       "       [[  9, 150],\n",
       "        [ 14, 268]]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi model CP: 87.30%\n",
      "Akurasi model Uplift: 61.22%\n",
      "ETP's confusion matrix result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>49</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          True  False\n",
       "Positive    76     48\n",
       "Negative    49     72"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETU's confusion matrix result\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[219,   3],\n",
       "        [ 19,   4]],\n",
       "\n",
       "       [[226,   2],\n",
       "        [ 15,   2]],\n",
       "\n",
       "       [[ 95,  52],\n",
       "        [ 37,  61]],\n",
       "\n",
       "       [[ 82,  56],\n",
       "        [ 42,  65]]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi model CP: 60.41%\n",
      "Akurasi model Uplift: 53.88%\n"
     ]
    }
   ],
   "source": [
    "# Proses evaluasi akurasi\n",
    "evaluasi_akurasi(hasil_prediksi_1)\n",
    "evaluasi_akurasi(hasil_prediksi_2)\n",
    "evaluasi_akurasi(hasil_prediksi_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 3.5.2. Evaluasi QINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pengurutan_data(df:pd.DataFrame):\n",
    "    \"\"\"Function untuk mengurutkan data\n",
    "    \"\"\"\n",
    "    # Siapkan dataframe baru untuk model CP dan Uplift\n",
    "    df_c = pd.DataFrame({'n':[], 'target_class':[]})\n",
    "    df_u = df_c.copy()\n",
    "    df_c['target_class'] = df['target_class']\n",
    "    df_u['target_class'] = df['target_class']\n",
    "    # Menambahkan urutan kuantil\n",
    "    df_c['n'] = df.proba_churn.rank(pct=True, ascending=False)\n",
    "    df_u['n'] = df.skor_uplift.rank(pct=True, ascending=False)\n",
    "    df_c['skor'] = df['proba_churn']\n",
    "    df_u['skor'] = df['skor_uplift']\n",
    "    # Proses pengurutan data    \n",
    "    df_c = df_c.sort_values(by='n').reset_index(drop=True)\n",
    "    df_u = df_u.sort_values(by='n').reset_index(drop=True)\n",
    "    df_c['model'], df_u['model'] = 'CP', 'Uplift'\n",
    "    return df_c, df_u\n",
    "\n",
    "\n",
    "def perhitungan_qini(df:pd.DataFrame):\n",
    "    \"\"\"Function untuk menghitung nilai QINI\n",
    "    \"\"\"\n",
    "    # Variabel control group dan treatment group\n",
    "    C, T = sum(df['target_class'] <= 1), sum(df['target_class'] >= 2)\n",
    "    df['cr'] = 0\n",
    "    df['tr'] = 0\n",
    "    df.loc[df.target_class  == 1,'cr'] = 1\n",
    "    df.loc[df.target_class  == 3,'tr'] = 1\n",
    "    df['cr/c'] = df.cr.cumsum() / C\n",
    "    df['tr/t'] = df.tr.cumsum() / T\n",
    "    # Hitung & masukkan nilai QINI kedalam dataframe\n",
    "    df['uplift'] = df['tr/t'] - df['cr/c']\n",
    "    df['random'] = df['n'] * df['uplift'].iloc[-1]\n",
    "    # Tambahkan q0 kedalam dataframe\n",
    "    q0 = pd.DataFrame({'n':0, 'uplift':0, 'target_class': None}, index =[0])\n",
    "    QINI = pd.concat([q0, df]).reset_index(drop = True)\n",
    "    return QINI\n",
    "\n",
    "\n",
    "def penggabungan_data(df_c:pd.DataFrame, df_u:pd.DataFrame):\n",
    "    \"\"\"Function untuk menambahkan kolom model dan\n",
    "    menggabungkan dataframe menjadi satu\n",
    "    \"\"\"\n",
    "    df_u['model'] = 'ETU'\n",
    "    df_c['model'] = 'ETP'\n",
    "    df = pd.concat([df_u, df_c]).sort_values(by='n').reset_index(drop = True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_qini(df:pd.DataFrame):\n",
    "    \"\"\"Function untuk mem-plotkan QINI\n",
    "    \"\"\"\n",
    "    # Menentukan data yang akan divisualisasikan\n",
    "    order = ['ETU','ETP']\n",
    "    ax = sns.lineplot(x='n', y=df.uplift, hue='model', data=df,\n",
    "                      style='model', palette=['red','deepskyblue'],\n",
    "                      style_order=order, hue_order = order)\n",
    "    # Pengaturan tampilan plot\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    plt.xlabel('Proportion targeted',fontsize=30)\n",
    "    plt.ylabel('Uplift',fontsize=30)\n",
    "    plt.subplots_adjust(right=1)\n",
    "    plt.subplots_adjust(top=1)\n",
    "    plt.legend(fontsize=30)\n",
    "    ax.tick_params(labelsize=24)\n",
    "    ax.legend(handles=handles[1:], labels=labels[1:])\n",
    "    ax.plot([0,1], [0,df.loc[len(df) - 1,'uplift']],'--', color='grey')\n",
    "    return ax\n",
    "\n",
    "\n",
    "def evaluasi_qini(hasil_prediksi:pd.DataFrame):\n",
    "    \"\"\"Function untuk menggabungkan semua proses evaluasi QINI\n",
    "    \"\"\"\n",
    "    df_c, df_u = pengurutan_data(hasil_prediksi)\n",
    "    qini_c, qini_u = perhitungan_qini(df_c), perhitungan_qini(df_u)\n",
    "    qini = penggabungan_data(qini_c, qini_u)\n",
    "    ax = plot_qini(qini)\n",
    "    return ax, qini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# hasil evaluasi QINI untuk dataset 1\n",
    "ax, qini_1 = evaluasi_qini(hasil_prediksi_1)\n",
    "plt.title('Qini Curve - Dataset 1',fontsize=20)\n",
    "plt.savefig('QINI_1_n.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hasil evaluasi QINI untuk dataset 2\n",
    "ax, qini_2 = evaluasi_qini(hasil_prediksi_2)\n",
    "plt.title('Qini Curve - Dataset 2',fontsize=20)\n",
    "plt.savefig('QINI_2_n.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# hasil evaluasi QINI untuk dataset 3\n",
    "ax, qini_3 = evaluasi_qini(hasil_prediksi_3)\n",
    "plt.title('Qini Curve - Dataset 3',fontsize=20)\n",
    "plt.savefig('QINI_3_n.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Menyiapkan bentuk kotak dan segitiga untuk swarmplot distribusi target class\n",
    "fig, ax = plt.subplots(1,1)\n",
    "a = ax.scatter([1,2],[3,4], marker='s')\n",
    "b = ax.scatter([1,2],[3,4], marker='^')\n",
    "square_mk, = a.get_paths()\n",
    "triangle_up_mk, = b.get_paths()\n",
    "a.remove()\n",
    "b.remove()\n",
    "def distribusi_target_class(df_1:pd.DataFrame,\n",
    "                            df_2:pd.DataFrame,\n",
    "                            df_3:pd.DataFrame,\n",
    "                            target_class:str):\n",
    "    \"\"\"Fungsi untuk memvisualisasikan swarmplot target class\"\"\"\n",
    "    # menambahkan kolom dataset\n",
    "    df_1['dataset'] = 'Dataset 1'\n",
    "    df_2['dataset'] = 'Dataset 2'\n",
    "    df_3['dataset'] = 'Dataset 3'\n",
    "    # menggabungkan dan mengurutkan ketiga dataset\n",
    "    df = pd.concat([df_1, df_2, df_3])\n",
    "    df = df.sort_values(by='n')[:round(len(df)/4)]\n",
    "    \n",
    "    \n",
    "    # menyiapkan swarmplot\n",
    "    ax = sns.swarmplot(data=df[df.target_class==target_class],\n",
    "                       x='dataset',\n",
    "                       y='n',\n",
    "                       hue='model',\n",
    "                       palette=['deepskyblue','red'],\n",
    "                       hue_order=['ETP', 'ETU'],\n",
    "                       order=['Dataset 1', 'Dataset 2', 'Dataset 3'], size=6.5)\n",
    "    collections = ax.collections\n",
    "    unique_colors = np.unique(collections[0].get_facecolors(),axis=0)\n",
    "    markers = [square_mk, triangle_up_mk]\n",
    "    for collection in collections:\n",
    "        paths = []\n",
    "        for current_color in collection.get_facecolors():\n",
    "            for possible_marker,possible_color in zip(markers, unique_colors):\n",
    "                if np.array_equal(current_color,possible_color):\n",
    "                    paths.append(possible_marker)\n",
    "                    break\n",
    "        collection.set_paths(paths)\n",
    "        \n",
    "    \n",
    "    # menambah pengaturan tampilan swarmplot\n",
    "    ax.tick_params(labelsize=24)   \n",
    "    ax.legend(collections[-2:],pd.unique(df.model))  \n",
    "    plt.ylabel('Decile',fontsize=20)\n",
    "    plt.xlabel('')\n",
    "    plt.subplots_adjust(right=1.5)\n",
    "    plt.subplots_adjust(top=1)\n",
    "    plt.legend(fontsize=20)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Memvisualisasikan swarmplot distribusi target class CN\n",
    "distribusi_target_class(qini_1, qini_2, qini_3, 0)\n",
    "plt.title('CN distribution in the top deciles',fontsize=25, y=1.05)\n",
    "plt.savefig('CN_n.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distribusi_target_class(qini_1, qini_2, qini_3, 1)\n",
    "plt.title('CR distribution in the top deciles',fontsize=25, y=1.05)\n",
    "plt.savefig('CR_n.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "distribusi_target_class(qini_1, qini_2, qini_3, 2)\n",
    "plt.title('TN distribution in the top deciles',fontsize=25, y=1.05)\n",
    "plt.savefig('TN_n.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "distribusi_target_class(qini_1, qini_2, qini_3, 3)\n",
    "plt.title('TR distribution in the top deciles',fontsize=25, y=1.05)\n",
    "plt.savefig('TR_n.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proses inverse nilai treatment\n",
    "df_model_inverse_1.treatment = df_model_inverse_1.treatment.replace({0: 1, 1: 0})\n",
    "df_model_inverse_2.treatment = df_model_inverse_2.treatment.replace({0: 1, 1: 0})\n",
    "df_model_inverse_3.treatment = df_model_inverse_3.treatment.replace({0: 1, 1: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menghitung kembali korelasi treatment\n",
    "display(korelasi_treatment(df_model_inverse_1).iloc[0,0])\n",
    "display(korelasi_treatment(df_model_inverse_2).iloc[0,0])\n",
    "display(korelasi_treatment(df_model_inverse_3).iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menambah feature target class pada ketiga dataset\n",
    "df_model_inverse_1, df_model_inverse_2, df_model_inverse_3 = deklarasi_target_class(df_model_inverse_1), \\\n",
    "deklarasi_target_class(df_model_inverse_2), deklarasi_target_class(df_model_inverse_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proses pemodelan machine learning\n",
    "hasil_prediksi_inverse_1 = model_machine_learning(df_model_inverse_1)\n",
    "hasil_prediksi_inverse_2 = model_machine_learning(df_model_inverse_2)\n",
    "hasil_prediksi_inverse_3 = model_machine_learning(df_model_inverse_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# hasil evaluasi QINI untuk dataset 1\n",
    "ax, qini_inverse_1 = evaluasi_qini(hasil_prediksi_inverse_1)\n",
    "plt.title('Qini Curve - Dataset 1',fontsize=20)\n",
    "plt.savefig('QINI_1_p.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# hasil evaluasi QINI untuk dataset 2\n",
    "ax, qini_inverse_2 = evaluasi_qini(hasil_prediksi_inverse_2)\n",
    "plt.title('Qini Curve - Dataset 2',fontsize=20)\n",
    "plt.savefig('QINI_2_p.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# hasil evaluasi QINI untuk dataset 3\n",
    "ax, qini_inverse_3 = evaluasi_qini(hasil_prediksi_inverse_3)\n",
    "plt.title('Qini Curve - Dataset 3',fontsize=20)\n",
    "plt.savefig('QINI_3_p.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Memvisualisasikan swarmplot distribusi target class CN\n",
    "distribusi_target_class(qini_inverse_1, qini_inverse_2, qini_inverse_3, 0)\n",
    "plt.title('CN distribution in the top deciles',fontsize=25, y=1.05)\n",
    "plt.savefig('CN_p.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribusi_target_class(qini_inverse_1, qini_inverse_2, qini_inverse_3, 1)\n",
    "plt.title('CR distribution in the top deciles',fontsize=25, y=1.05)\n",
    "plt.savefig('CR_p.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distribusi_target_class(qini_inverse_1, qini_inverse_2, qini_inverse_3, 2)\n",
    "plt.title('TN distribution in the top deciles',fontsize=25, y=1.05)\n",
    "plt.savefig('TN_p.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distribusi_target_class(qini_inverse_1, qini_inverse_2, qini_inverse_3, 3)\n",
    "plt.title('TR distribution in the top deciles',fontsize=25, y=1.05)\n",
    "plt.savefig('TR_p.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
